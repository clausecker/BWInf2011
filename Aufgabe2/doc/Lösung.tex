\documentclass{scrartcl}

\usepackage[biolinum]{libertine}
\usepackage[euler-digits,small]{eulervm}

\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{ngerman}
\usepackage{verbatim}
\usepackage{url}
\usepackage{parskip}
\usepackage{fancyvrb}
\usepackage{xcolor}

%Definitionen für den Formatierer
\include{definitions}

\title{Lösung der Aufgabe~2}
\subtitle{des 30.~Bundeswettbewerbs Informatik}
\author{Robert Clausecker, Alexandra Piloth}
%\date{}

% Syntaxdefinitionen
\setlength{\parskip}{0.5em plus0.5em minus0.5em}
\setlength{\parindent}{1em}
\newcommand{\ftwo}{\ensuremath{\mathbb F_2}}
\DeclareMathOperator{\bigO}{O}
\newcommand{\xor}{\oplus}
\def\UrlFont{\it}

\begin{document}

\maketitle

\section*{Vorbemerkungen}
Im Folgenden bezeichne $0$ den logischen Wert \emph{falsch} und $1$ den
logischen Wert \emph{wahr}. $a\land b$ sei die Konjunktion (and) von $a$
und $b$, $a\xor b$ sei analog die Kontravalenz (xor). Insbesondere gilt:
$a\xor b=a+b\mod 2$ und $a\land b=a\cdot b\mod 2$.

Die Implementationen der beschriebenen Algorithmen finden sich im Anhang.

\section{Grundidee}
Wir betrachten eine Anordnung von Schaltern und Lampen als \emph{lineares
Gleichungssystem} im Körper \ftwo.  Dieser hat die Elemente $1$ (Lampe an bzw.
Schalter gedrückt) und $0$ (Lampe aus bzw. Schalter nicht gedrückt).

Durch allgemein bekannte Algorithmen, wie das Gaußverfahren, lässt sich eine
Schalterstellung zum Ausschalten aller Lampen in $\bigO(n^3)$ finden; $n$ ist
hierbei die Anzahl der Schalter bzw. Lampen. Nimmt man an, dass ein Bitvektor
der Länge $n$ in ein Maschinenwort passt, so kann eine Lösung sogar in $\bigO(
n^2)$ gefunden werden. Herauszufinden, ob eine Schaltung brauchbar ist, hat eine
ähnliche Komplexität, weil das ein Teilproblem des o.\,g. Problems ist.

\section{Darstellung als Gleichungssystem}
Seien $s_1, s_2,\dots, s_n$ die Zustände der Schalter und $l_1, l_2,\dots,l_n$
die Ausgangszustände der dazu gehörigen Lampen. Jede Lampe wird durch eine Reihe
von Schaltern $s_\alpha, s_\beta,\dots$ umgeschaltet. Diese Umschaltungen lassen
sich als XOR-Operationen darstellen. Der Zustand einer Lampe ist also
\begin{equation}
l_k \xor s_\alpha \xor s_\beta \xor s_\gamma \xor \cdots
\end{equation}
Eine Schalterstellung, welche die Lampe $l_k$ ausschaltet ist damit zugleich
eine Lösung der Gleichung
\begin{equation}
s_\alpha \xor s_\beta \xor s_\gamma \xor \cdots = l_k\label{firstEq}
\end{equation}
Um diese Gleichungen in ein einheitliches Format zu bringen, führen
wir die Koeffizienten $v_{a,b}$ ein. $v_{a,b}$ ist $1$, genau dann wenn Lampe
$l_a$ mit Schalter $s_b$ verbunden ist. Somit lässt sich Gleichung~\ref{firstEq}
als
\begin{equation}
v_{k,1}\land s_1\xor v_{k,2}\land s_2\xor\cdots\xor v_{k,k}\land s_k=l_k
\end{equation}
ausdrücken.

Betrachtet man nun $\xor$ und $\land$ als Addition und Multiplikation im Körper
\ftwo, dann kann man nun die $n$ Gleichungen der Lampen als lineares
Gleichungssystem in den Variablen $s_1$ bis $s_n$ auffassen:
\begin{equation}
\begin{cases}
  v_{1,1}s_1+v_{1,2}s_2+\dots+v_{1,n}s_n&=l_1\\
  v_{2,1}s_1+v_{2,2}s_2+\dots+v_{2,n}s_n&=l_2\\
  \hfil\vdots\hfil&\hfil\vdots\hfil\\
  v_{n,1}s_1+v_{n,2}s_n+\dots+v_{n,n}s_n&=l_n\\
\end{cases}
\end{equation}

Dieses lässt sich wiederum durch die Koeffizientenmatrix
\begin{equation}
M=
\begin{pmatrix}
  v_{1,1}&v_{1,2}&\cdots&v_{1,n}\\
  v_{2,1}&v_{2,2}&\cdots&v_{2,n}\\
  \vdots &\vdots &\ddots&\vdots\\
  v_{1,n}&v_{2,n}&\cdots&v_{n,n}
\end{pmatrix}
\end{equation}
und den Spaltenvektor $A$ der Ausgangszustände $l_1$ bis $l_n$ darstellen. Für
ein effizientes Arbeiten speichern wir jede Zeile von $M$ in ein- oder mehreren
Maschinenwörtern. Da jeder Eintrag in der Matrix nur ein Bit lang ist, kann man
so über eingebaute Bitoperationen ganze Zeilen effizient addieren. Unter der
Annahme, dass eine Zeile komplett in ein Maschinenwort passt, kann man zwei
Zeilen in $\bigO(1)$ mit einem XOR addieren.

\section{Lösbarkeit einer einzelnen Konfiguration}
\label{singleConf}
Wir betrachten nun eine vollständige Konfiguration einer Schaltung, bestehend
aus der Schaltung $M$ und den Ausgangszuständen $A$. In (\ref{exampleGame}) ist
die Konfiguration angegeben, die in der ersten Teilaufgabe zu analysieren ist.
Dabei ist links $M$ und rechts -- durch einen Balken abgeteilt -- $A$ angegeben.
\begin{equation}
M\vert A=\left(
\begin{array}{ccccccc|c}
  1&1&0&0&0&0&1&0\\
  1&1&1&0&0&0&0&0\\
  0&1&1&1&0&0&0&1\\
  0&0&1&1&1&0&0&0\\
  0&0&0&1&1&1&0&1\\
  0&0&0&0&1&1&1&0\\
  1&0&0&0&0&1&1&1 
\end{array}\right)\label{exampleGame}
\end{equation}

Zunächst wenden wir das \emph{Gaußsche Eliminationsverfahren} an, um die
Matrix in Stufenform zu überführen. Damit erhält man einen Überblick über die
Lösbarkeit des Gleichungssystems. Es gilt: Wenn die Determinante, also das
Produkt der Werte in der Hauptdiagonale, ungleich $0$ ist, dann existiert genau
eine Lösung. Wenn nicht, dann existiert entweder keine oder höchstens so viele
verschiedene Lösungen, wie Nullen in der Diagonale vorhanden sind.

Wenn die Determinante $0$ beträgt, dann befinden sich am Ende der Matrix ein-
oder mehrere Leerzeile (Zeile der Form $(0\ 0\ \dots\ 0\,|\,\dots)$). Dies muss
so sein,weil durch die Stufenform in jeder folgenden Zeile mindestens ein
Eintrag weniger als in der überstehenden stehen muss. Weil die Matrix
quadratisch ist, muss für den Fall, dass die Differenz der Anzahl relevanter
Einträge zweier aufeinander folgender Zeilen größer als $1$ ist, mindestens eine
Leerzeile am Ende stehen. Eine derartig transformierte Matrix mit Determinante
$0$ ist in (\ref{echelonZero}) zu sehen:
\begin{equation}
\left(\begin{array}{cccccc|c}
  1&0&0&0&1&0&1\\
  0&0&1&1&1&1&1\\
  0&0&0&1&0&1&0\\
  0&0&0&0&0&1&0\\
  0&0&0&0&0&0&0\\
  0&0&0&0&0&0&1\\
\end{array}\right)\label{echelonZero}
\end{equation}

Das Gleichungssystem hat nun entweder keine oder $2^n$ Lösungen, wobei $n$ die
Anzahl der Leerzeilen ist. Ersterer Fall tritt genau dann ein, wenn der zur
Zeile $k$ zugehörige Wert in $A$ ungleich $0$ ist, also es eine Zeile der Form
$0=1$ gibt. Beide Fälle sind in (\ref{echelonZero}) gezeigt; der Erste in der
vorletzten, der Zweite in der letzten Zeile.

Für den Fall, dass es nun Lösungen gibt, kann man das Gauß-Jordan-Verfahren mit
der Einschränkung anwenden, dass im Falle eines Sprunges (also wenn in der
überstehenden Zeile mehr als eine Spalte von links mehr ausgefüllt ist), die
übersprungenen Variablen beliebig gesetzt werden können. Offensichtlich ergibt
dies zwei Lösungen pro übersprungener Spalte. Da es genauso viele Leerzeilen wie
übersprungene Spalten gibt, ist die Anzahl der Lösung wie oben beschrieben
$2^n$.

Nach Anwendung des Gauß-Verfahrens auf die Matrix (\ref{exampleGame}) ergibt
sich die Stufenform
\begin{equation}
\left(\begin{array}{ccccccc|c}
  1&1&0&0&0&0&1&0\\
  0&1&0&0&0&1&0&1\\
  0&0&1&1&0&1&0&0\\
  0&0&0&1&0&1&1&0\\
  0&0&0&0&1&0&1&1\\
  0&0&0&0&0&1&1&1\\
  0&0&0&0&0&0&1&0
\end{array}\right).
\end{equation}
Die Determinante ist $1$, somit existiert genau eine Lösung. Nun kann man das
Gauß-Jordan-Verfahren anwenden, um diese zu bestimmen. Es ergibt sich die
reduzierte Stufenform
\begin{equation}
\left(\begin{array}{ccccccc|c}
  1&0&0&0&0&0&0&0\\
  0&1&0&0&0&0&0&0\\
  0&0&1&0&0&0&0&0\\
  0&0&0&1&0&0&0&1\\
  0&0&0&0&1&0&0&1\\
  0&0&0&0&0&1&0&1\\
  0&0&0&0&0&0&1&0
\end{array}\right)
\end{equation}
aus der man direkt die Lösung des zu (\ref{exampleGame}) gehörigen
Gleichungssystems direkt ablesen kann:
\begin{equation}
s_1 = 0,\quad
s_2 = 0,\quad
s_3 = 0,\quad
s_4 = 1,\quad
s_5 = 1,\quad
s_6 = 1,\quad
s_7 = 0.
\end{equation}

\section{Bestimmung brauchbarer Schaltungen}
Eine Schaltung ist genau dann brauchbar, wenn es für jeden Tupel von
Ausgangszuständen $(l_1,l_2,\dots,l_n)$ genau eine Kombination von
Schalterzuständen $(s_1,s_2,\dots,s_n)$ gibt, sodass diese alle Lampen
ausschaltet. Das dies gilt, lässt sich durch Anwendung des Schubfachprinzipes
zeigen: Es gibt bei $n$ Lampen genau $2^n$ Kombinationen von Lampenzuständen und
ebenso viele Kombinationen von Schalterzuständen. Offensichtlich kann jede
Schalterkombination genau eine Lampenkombination ausschalten. Gäbe es eine
Lampenkombination, die mehr als eine Lösung hat, muss es also zwangsläufig eine
Andere geben, die keine Lösung hat. Dies ist ein Widerspruch zur Annahme, dass
alle Lampenkombinationen lösbar sind.

Es genügt also, nur die Determinanten zu betrachten, weil diese Aufschluss über
die eindeutige Lösbarkeit einer Schaltung geben, wie hier am Beispiel der
zweiten Schaltung im Aufgabenblatt. Ihre Koeffizientenmatrix $M$ ist
\begin{equation}
\begin{pmatrix}
  1&1&0&1&0&0&0&0&0\\
  1&1&1&0&1&0&0&0&0\\
  0&1&1&0&0&1&0&0&0\\
  1&0&0&1&1&0&1&0&0\\
  1&0&1&0&1&0&1&0&1\\
  0&0&1&0&1&1&0&0&1\\
  0&0&0&1&0&0&1&1&0\\
  0&0&0&0&1&0&1&1&1\\
  0&0&0&0&0&1&0&1&1
\end{pmatrix}\label{m9}
\end{equation}
Nach Anwendung des Gaußschen Eliminationsverfahrens ergibt sich die
Stufenmatrix
\begin{equation}
\begin{pmatrix}
  1&1&0&1&0&0&0&0&0\\
  0&1&0&0&1&0&1&0&0\\
  0&0&1&1&0&0&0&0&1\\
  0&0&0&1&1&1&1&0&1\\
  0&0&0&0&1&1&0&1&1\\
  0&0&0&0&0&1&0&1&0\\
  0&0&0&0&0&0&1&1&0\\
  0&0&0&0&0&0&0&1&1\\
  0&0&0&0&0&0&0&0&1
\end{pmatrix},
\end{equation}
deren Determinante $1$ ist. Das Gleichungssystem hat unabhängig von den
Ausgangszuständen genau eine Lösung, damit ist die Schaltung brauchbar.

\section{Bestimmung von Lösungsschemen}
Ein weiterer Teil der Aufgabenstellung ist es, eine allgemeine Lösungsformel
für beliebige Ausgangszustände zu finden. Dies ist nur möglich, wenn die
Schaltung nach o.\,g. Kriterium brauchbar ist, ansonsten kann man nur
spezifische Fälle mit der in Abschnitt \ref{singleConf} beschriebenen Methode
lösen.

Die Idee der allgemeinen Lösung ist es, das Gleichungssystem derart zu
transformieren, dass die Ausgangszustände der Lampen $l_1\dots l_n$ die
Unbekannten und die Zustände der Schalter $s_1\dots s_n$ die Glieder auf der
rechten Seite sind. In ein solches Gleichungssystem kann man nun einfach einfach
den Ausgangszustand einsetzen und erhält eine Lösung in Form der nötigen
Schalterzustände.
\begin{equation}\label{transposedSys}
\begin{cases}
  u_{1,1}l_1+u_{1,2}l_2+\dots+u_{1,n}l_n&=s_1\\
  u_{2,1}l_1+u_{2,2}l_2+\dots+u_{2,n}l_n&=s_2\\
  \hfil\vdots\hfil&\hfil\vdots\hfil\\
  u_{n,1}l_1+u_{n,2}l_n+\dots+u_{n,n}l_n&=s_n\\
\end{cases}
\end{equation}

Glücklicherweise kann man die Koeffizienten $u_{i,j}$ dieses Systems recht
einfach berechnen: Man fügt hierzu an die rechte Seite der ursprünglichen
Koeffizientenmatrix $M$ eine Einheitsmatrix der selben Größe an und verwendet
diese anstatt von $A$ in der Gauß-Jordan-Elimination. Am Ende ist die
linke Matrix eine Einheitsmatrix, während die rechte Matrix, $M'$, die gesuchte
Matrix der Koeffizienten $u_{i,j}$ ist.
\begin{align}
\text{vorher:}\quad&
\left(\begin{array}{cccc|cccc}
  v_{1,1}&v_{1,2}&\cdots&v_{1,n}&1&0&\cdots&0\\
  v_{2,1}&v_{2,2}&\cdots&v_{2,n}&0&1&\cdots&0\\
  \vdots&\vdots&\ddots&\vdots&\vdots&\vdots&\ddots&\vdots\\
  v_{n,1}&v_{n,2}&\cdots&v_{n,n}&0&0&\cdots&1
\end{array}\right)\\
\text{nachher:}\quad&
\left(\begin{array}{cccc|cccc}
  1&0&\cdots&0&u_{1,1}&u_{1,2}&\cdots&u_{1,n}\\
  0&1&\cdots&0&u_{2,1}&u_{2,2}&\cdots&u_{2,n}\\
  \vdots&\vdots&\ddots&\vdots&\vdots&\vdots&\ddots&\vdots\\
  0&0&\cdots&1&u_{n,1}&u_{n,2}&\cdots&u_{n,n}\\
\end{array}\right)
\end{align}

Es ist nicht schwer zu erkennen, warum dies funktioniert: Bei der normalen
Gauß-Jordan-Elimination verwendet man die Ausgangszustände im Vektor $A$. Da die
verwendeten Operationen aber nur Addition zweier Reihen sowie Einsetzung sind,
kann man einen Eintrag in $A$ auch als Summe aller Ausgangszustände mit
geeigneten Koeffizienten darstellen. Am Anfang sind nur diejenigen Koeffizienten
$1$, die zur jeweiligen Zeile gehören -- dies ist die Einheitsmatrix. Am Ende
ist hingegen die linke Matrix eine Einheitsmatrix. Schreibt man dies wiederum
als Gleichungssystem, so ist die linke Matrix die rechte Seite von
(\ref{transposedSys}) und umgekehrt.

\pagebreak[2]
Wendet man diese Variante des Gauß-Jordan-Verfahrens auf die Matrix (\ref{m9})
an, dann entsteht am Ende folgende Matrix auf der rechten Seite:
\begin{equation}
\begin{pmatrix}
  1&0&1&0&0&1&1&1&0\\
  1&1&1&1&1&1&0&0&0\\
  1&0&1&1&0&0&0&1&1\\
  1&1&0&1&1&0&1&1&0\\
  1&0&1&0&1&0&1&0&1\\
  0&1&1&0&1&1&0&1&1\\
  1&1&0&0&0&1&1&0&1\\
  0&0&0&1&1&1&1&1&1\\
  0&1&1&1&0&0&1&0&1
\end{pmatrix}.
\end{equation}
Die Koeffizienten obenstehender Matrix kann man jetzt einfach nach dem in (\ref
{transposedSys}) angegebenen Schema in ein allgemeines Lösungsschema für die
zweite Schaltung im Aufgabenblatt einsetzen. Um die Richtigkeit des
Lösungsschemas nachzuweisen kann man außerdem eine Probe durchführen. Dafür
setzt man für alle $s_n$ im ursprünglichen Gleichungssystem die entsprechenden
Zeilen aus $M'$ ein. Da man nach der Einsetzung sowohl links als auch rechts
Terme in $l_n$ hat, muss bei einer korrekt invertierten Matrix zwangsläufig die
Einheitsmatrix auf der linken Seite entstehen.

Es ist leicht zu erkennen, dass diese Operation gerade die Matrixmultiplikation
ist. Als alternative Interpretation des oben beschriebenen erweiterten
Gauß-Jordan-Verfahrens kann man sagen, dass mit $M'$ die inverse Matrix zu $M$
berechnet wird. Sei $E$ die Einheitsmatrix der selben Größe wie $M$ und $M'$.
Dann muss für eine korrekt aus $M$ berechnete inverse Matrix $M'$
\begin{equation}
M\cdot M' = E
\end{equation}
gelten. Diese Matrixmultiplikation lässt sich effizient berechnen, indem man für
jeder Zeile $n$ von $M$ genau die Zeilen $k$ in $M'$ addiert, für die $v_{n,k}
=1$ ist.

\section{Erzeugung zufälliger brauchbarer Schaltungen}
Dieser Teil der Aufgabenstellung ist recht eindeutig. Wir haben die Erzeugung
implementiert, indem wir mit Hilfe eines Zufallszahlengenerators Matrizen der
gewünschten Größe befüllt und anschließend auf Lösbarkeit getestet haben. Viel
interessanter als dieser Vorgang an sich ist hingegen die Analyse der Effizienz:
Wie viele Matrizen einer Größe $n\times n$ muss man im Mittel generieren,
bis man eine brauchbare gefunden hat?

Die Antwort auf diese Frage ist nicht trivial. Zuerst ist es nötig, die
Wahrscheinlichkeit der Lösbarkeit einer zufällig gewählten Matrix bestimmter
Größe zu bestimmen. Eine Recherche im Internet zeigt, dass dieses Problem von
anderen Mathematikern bereits behandelt wurde.\footnote{Vgl. Gabe Cunningham,
\url{http://www-math.mit.edu/~dav/genlin.pdf}} Die Anzahl der Matrizen der Größe
$n\times n$ beträgt $2^{n^2}$, die Anzahl der lösbaren (also nicht-singulären)
Matrizen ist nach obrigem Dokument $\prod_{k=0}^{n-1}(2^n-2^k)$. Die
Wahrscheinlichkeit $p_n$, dass eine zufällig gewählte Matrix der Größe
$n\times n$ lösbar ist, beträgt demnach
\begin{equation}
p_n=
2^{-n^2}\prod\limits_{k=0}^{n-1}(2^n-2^k)=
\prod_{k=0}^{n-1}\frac{2^n-2^k}{2^n}=
\prod_{k=0}^{n-1}(1-2^{-k}).
\end{equation}

Betrachtet man die Werte von $\prod_{k=0}^{n-1}(1-2^{-k})$ für verschiedene
$n$, so scheint der Term für $n\to\infty$ gegen einen Wert etwas größer als
$\frac27$ zu konvergieren:
\begin{equation}
p_\infty=\lim_{n\to\infty}\prod_{k=0}^{n-1}(1-2^{-k})\approx 0{,}288788
\end{equation}

Dies zu zeigen ist nicht schwer: Offensichtlichtlich ist $p_n$ streng monoton
fallend, da bei Inkrementierung von $n$ das Produkt um einen Faktor
$0<1-2^{-k}<1$ erweitert wird. Andererseits ist das Produkt nach unten
beschränkt, da es nie negativ wird. Da jede streng monoton fallende, nach unten
beschränkte Folge konvergiert, muss $\lim\limits_{n\to\infty}p_n$ existieren.

Sei $A_n$ nun die Anzahl der Zufallsmatrizen der Größe $n\times n$, die man im
Mittel erzeugen muss, bis man eine lösbare erhält. Man kann zwei Fälle
unterscheiden: Mit einer Wahrscheinlichkeit von $p_n$ braucht man nur einen
Versuch. In allen anderen Fällen braucht man hingegen genau einen Versuch mehr
als im Mittel, weil $A$ nicht von der Anzahl der Versuche an sich abhängt. Es
ist somit $A_n=A_np_n+(A_n+1)(1-p_n)$. Umformung nach $A_n$ ergibt die
einfache Form
\begin{equation}
A_n=p_n^{-1}.
\end{equation}
Da $p_n$ streng monoton fallend ist, ist $A_n$ dann am größten, wenn $n$ gegen
Unendlich geht. Somit ist
\begin{equation}
\max A_n = A_\infty = p_\infty^{-1} \approx 3{,}46274.
\end{equation}
Man muss also im Mittel ca. $3{,}5$ Schaltungen erzeugen, bis man eine
brauchbare gefunden hat.

Offensichtlich ist $A_n=\bigO(1)$. Weil man zur Erzeugung einer Matrix $\bigO(n^
2)$ Zufallsbits erzeugen muss, und das zur Überprüfung auf Lösbarkeit benötigte
Gaußsche Eliminationsverfahren eine Komplexität von $\bigO(n^3)$ hat, ist die
Komplexität der zufälligen Erzeugung einer brauchbaren Schaltung im mittleren
und besten Fall $\bigO(1)\cdot\left(\bigO(n^3)+\bigO(n^2)\right)=\bigO(n^3)$.
Man kann keine genauere Aussage treffen, weil der Algorithmus randomisiert ist
und nicht garantiert terminiert. Wenn er allerdings terminiert, dann liefert er
immer ein korrektes Ergebnis. Es handelt sich also um einen
\emph{Las-Vegas-Algorithmus}.

\section{Implementation}
Es folgt ein vollständiger Abdruck des Quelltextes. Dieser ist in vier Einheiten
unterteilt worden, die jeweils einen anderen verschiedenen Teil der Aufgabe
lösen:

\begin{description}
\item[Matrix] Enthält die Definition der verwendeten Datentypen \texttt
  {MatrixRow} und \texttt{Matrix}, wobei letzterer nur ein Synonym für eine
  Liste von Zeilen (\texttt{[MatrixRow]}) ist. Außerdem sind noch ein paar
  Hilfsfunktionen, die nicht viel mit den eigentlichen Algorithmen zu tun haben
  implementiert.
\item[Gauss] Enthält die Implementierungen der Gauß-Elimination und des
  Gauß-Jordan-Verfahrens sowie einige Funktionen um diese leichter zu verwenden.
\item[Generation] Enthält Code, um (brauchbare) Schaltungen zu erzeugen.
\item[Main] Enthält Code zur Verarbeitung der Kommandozeilenargumente sowie zur
  Ein- und Ausgabe.
\end{description}

\newcommand{\listSec}[1]{%
  \subsection*{#1}
  \input #1.hs.tex
}

\listSec{Matrix}
\listSec{Gauss}
\listSec{Generation}
\listSec{Main}
\end{document}
